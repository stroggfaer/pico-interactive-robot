# AI –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–æ–±–æ—Ç —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–µ—Ä–µ–∑ –ø–æ—Ä—Ç COM5 RP2040 Raspberry Pi Pico Bootloader v3.0 v1.0
# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥–æ–ª–æ—Å–æ–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ gtts
# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—É–¥–∏–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ pydub
# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–µ—Ç—å—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ requests
# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ—Ç–æ–∫–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ threading
# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å UUID –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ uuid
# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ os
# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å JSON –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ json
# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º —Ä–µ—á–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ speech_recognition
# GIThab: https://github.com/stroggfaer/pico-interactive-robot/tree/main
# –ê–≤—Ç–æ—Ä: Rendzhi
# command_ai.py
import serial
import time
import json
import requests
import random
import re
import speech_recognition as sr
import threading
import os
import uuid
from gtts import gTTS
import pygame
import wave
import contextlib
from pydub import AudioSegment
import scipy.io.wavfile as wavfile
import numpy as np

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"
OPENROUTER_API_KEY = "" # –ö–ª—é—á –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ OpenRouter API
MODEL_NAME = "nousresearch/deephermes-3-mistral-24b-preview:free"
ROBOT_VOICE_EFFECT = 70 # –£–ø—Ä–∞–≤–ª—è–µ—Ç "—Ç–æ–Ω–æ–º" –≥–æ–ª–æ—Å–∞

TTS_MODE = "gtts" # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å "gtts" –∏–ª–∏ "elevenlabs"
ROBOT_VOICE_LANG = "ru" # –Ø–∑—ã–∫ –≥–æ–ª–æ—Å–∞
TEMP_AUDIO_DIR = os.path.join(os.path.dirname(__file__), "temp") # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤

if not os.path.exists(TEMP_AUDIO_DIR):
    os.makedirs(TEMP_AUDIO_DIR)

pygame.mixer.init()

recognizer = sr.Recognizer()
ser = serial.Serial('COM5', 115200, timeout=1)
time.sleep(2)

EMOTIONS = [
    "neutral", "angry_talking", "smile", "smile_love",
    "embarrassed", "scary", "happy", "sad",
    "surprise", "happy_circle", "talking"
]

TALKING_EMOTIONS = ["talking"]
FINAL_EMOTIONS = ["neutral"]

def get_wav_duration(file_path):
    with contextlib.closing(wave.open(file_path, 'r')) as f:
        frames = f.getnframes()
        rate = f.getframerate()
        duration = frames / float(rate)
        return duration

def apply_robot_effect(wav_path):
    sample_rate, data = wavfile.read(wav_path)
    t = np.linspace(0, len(data) / sample_rate, num=len(data))
    modulator = np.sin(2 * np.pi * ROBOT_VOICE_EFFECT * t)
    robotized = (data * modulator).astype(data.dtype)
    robot_wav_path = wav_path.replace('.wav', '_robot.wav')
    wavfile.write(robot_wav_path, sample_rate, robotized)
    return robot_wav_path

def speak_and_send(text, ser, emotion, intensity=1.0, volume=1.0, mouth_speed=0.2):
    if not text.strip():
        return

    def process():
        try:
            tts = gTTS(text=text, lang=ROBOT_VOICE_LANG, slow=False)
            unique_id = uuid.uuid4().hex
            mp3_path = os.path.join(TEMP_AUDIO_DIR, f"robot_voice_{unique_id}.mp3")
            wav_path = os.path.join(TEMP_AUDIO_DIR, f"robot_voice_{unique_id}.wav")
            tts.save(mp3_path)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º MP3 –≤ WAV
            audio = AudioSegment.from_mp3(mp3_path)
            audio.export(wav_path, format="wav")

            wav_path = apply_robot_effect(wav_path)

            real_duration = get_wav_duration(wav_path)

            json_command = json.dumps({
                "emotion": emotion if emotion in TALKING_EMOTIONS else "talking",
                "talking_emotion": emotion,
                "text": text,
                "mouth_speed": mouth_speed,
                "duration": real_duration,
                "intensity": intensity,
                "volume": volume
            }, ensure_ascii=False)

            ser.write((json_command + "\r\n").encode('utf-8'))
            print(f"Sent: {json_command}")

            pygame.mixer.music.load(wav_path)
            pygame.mixer.music.play()

            while pygame.mixer.music.get_busy():
                time.sleep(0.1)

            pygame.mixer.music.stop()
            pygame.mixer.quit()
            pygame.mixer.init()

            if os.path.exists(mp3_path):
                os.remove(mp3_path)
            if os.path.exists(wav_path):
                os.remove(wav_path)

            try:
                response = ser.readline().decode('utf-8').strip()
                print(f"Response: {response}")
            except Exception as e:
                print(f"[ERROR] Reading response: {e}")

        except Exception as e:
            print(f"[gTTS ERROR] {e}")

    threading.Thread(target=process).start()

def detect_emotion_simple(text):
    if not text:
        return "neutral"
        
    text_lower = text.lower()
    emotion_triggers = {
        "smile": ["—Ö–∞", "–∞—Ö–∞—Ö", "–ª–æ–ª", "—Å–º–µ—à–Ω–æ", "–≤–µ—Å–µ–ª–æ", "–∑–∞–±–∞–≤–Ω–æ", "—Ö–µ—Ö–µ"],
        "smile_love": ["–ª—é–±–ª—é", "–æ–±–æ–∂–∞—é", "–º–∏–ª–∞—è", "‚ù§Ô∏è", "‚ô•Ô∏è", "–º–∏–ª—ã–π", "–ø—Ä–µ–ª–µ—Å—Ç—å", "–∫—Ä–∞—Å–æ—Ç–∞"],
        "scary": ["–±–æ—é—Å—å", "—Å—Ç—Ä–∞—à–Ω–æ", "—É–∂–∞—Å", "–∂—É—Ç–∫–æ", "–∫–æ—à–º–∞—Ä", "–ø–∞–Ω–∏–∫–∞"],
        "sad": ["–≥—Ä—É—Å—Ç–Ω–æ", "–ø–µ—á–∞–ª—å–Ω–æ", "–∂–∞–ª—å", "—Ç–æ—Å–∫–∞", "–≥—Ä—É—Å—Ç—å", "–ø–µ—á–∞–ª—å", "–ø–ª–æ—Ö–æ"],
        "surprise": ["—É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ", "–æ–≥–æ", "–≤–∞—É", "–Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ", "–ø–æ—Ä–∞–∑–∏—Ç–µ–ª—å–Ω–æ", "–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ", "!"],
        "embarrassed": ["—Å—Ç—ã–¥–Ω–æ", "—Å–º—É—â–∞—é—Å—å", "–Ω–µ–ª–æ–≤–∫–æ", "–∏–∑–≤–∏–Ω–∏", "–ø—Ä–æ—Å—Ç–∏", "—Å—Ç–µ—Å–Ω—è—é—Å—å"],
        "angry_talking": ["–∑–ª–æ–π", "–∑–ª–æ—Å—Ç—å", "—Ä–∞–∑–¥—Ä–∞–∂–∞–µ—Ç", "–±–µ—Å–∏—Ç", "–Ω–µ–Ω–∞–≤–∏–∂—É", "–≥–Ω–µ–≤"],
        "happy": ["—Ä–∞–¥–æ—Å—Ç—å", "—Å—á–∞—Å—Ç—å–µ", "–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ", "—Å—É–ø–µ—Ä", "–æ—Ç–ª–∏—á–Ω–æ", "–∫–ª–∞—Å—Å", "–∫—Ä—É—Ç–æ"]
    }

    if "?" in text:
        for emotion, triggers in emotion_triggers.items():
            if any(trigger in text_lower for trigger in triggers):
                return emotion
        return "talking"

    if "!" in text:
        for emotion, triggers in emotion_triggers.items():
            if any(trigger in text_lower for trigger in triggers):
                return emotion
        return "happy"

    max_triggers = 0
    detected_emotion = "neutral"
    
    for emotion, triggers in emotion_triggers.items():
        trigger_count = sum(1 for trigger in triggers if trigger in text_lower)
        if trigger_count > max_triggers:
            max_triggers = trigger_count
            detected_emotion = emotion

    if max_triggers > 0:
        return detected_emotion

    if text.strip():
        return "talking"

    return "neutral"

def get_emotion_from_context(text):
    emotion = detect_emotion_simple(text)

    prompt = f"""
–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç —Å —ç–º–æ—Ü–∏–µ–π: {emotion}.
–û—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –≤ —ç—Ç–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏.
–§—Ä–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{text}"

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞:
{{
    "emotion": "{emotion}",
    "text": "—Ç–≤–æ–π –æ—Ç–≤–µ—Ç –∑–¥–µ—Å—å"
}}
"""

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }

    try:
        response = requests.post(OPENROUTER_API_URL, headers=headers, json=payload)
        response.raise_for_status()
        message = response.json()["choices"][0]["message"]["content"]
        print(f"ü§ñ AI response: {message}")
        match = re.search(r'\{.*?\}', message, re.DOTALL)
        if match:
            emotion_data = json.loads(match.group())
            if "text" in emotion_data:
                result = {"emotion": emotion, "text": emotion_data["text"]}
                print(f"‚ú® Final response: {result}")
                return result
    except Exception as e:
        print(f"üî¥ –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenRouter: {e}")

    return {"emotion": emotion, "text": "–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –ø–æ–ø—Ä–æ–±—É–π –ø–æ–≤—Ç–æ—Ä–∏—Ç—å!"}

def recognize_speech():
    try:
        with sr.Microphone() as source:
            print("üéôÔ∏è –ì–æ–≤–æ—Ä–∏ –≤ –º–∏–∫—Ä–æ—Ñ–æ–Ω...")
            recognizer.adjust_for_ambient_noise(source, duration=1)
            audio = recognizer.listen(source, timeout=6, phrase_time_limit=12)
            text = recognizer.recognize_google(audio, language='ru-RU')
            print(f"üü¢ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text}")
            return text
    except Exception as e:
        print(f"üî¥ –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏: {e}")
        return ""

def change_speed(wav_path, speed=1.2):
    sound = AudioSegment.from_wav(wav_path)
    sound_with_altered_frame_rate = sound._spawn(sound.raw_data, overrides={
         "frame_rate": int(sound.frame_rate * speed)
      })
    sound_with_altered_frame_rate = sound_with_altered_frame_rate.set_frame_rate(sound.frame_rate)
    new_path = wav_path.replace('.wav', f'_speed{speed}.wav')
    sound_with_altered_frame_rate.export(new_path, format="wav")
    return new_path

initial = ser.readline().decode('utf-8').strip()
print(f"Initial: {initial}")
ser.write((json.dumps({"emotion": "neutral", "duration": 2.0, "intensity": 1.0, "volume": 0.3}) + "\r\n").encode('utf-8'))

input_choice = input("üéôÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω? (–¥–∞/–Ω–µ—Ç): ").lower()
use_mic = input_choice == "–¥–∞"

while True:
    if use_mic:
        user_input = recognize_speech()
    else:
        user_input = input("> ")

    if user_input.lower() == "q":
        break
    if not user_input:
        continue

    emotion_data = get_emotion_from_context(user_input)
    emotion = emotion_data["emotion"]
    llama_response = emotion_data["text"]

    print(f"\nüü¢ –≠–º–æ—Ü–∏—è: {emotion}")
    print(f"üü¢ –û—Ç–≤–µ—Ç: {llama_response}")

    if llama_response:
        speak_and_send(llama_response, ser, emotion)
        final_emotion = random.choice(FINAL_EMOTIONS)
        ser.write((json.dumps({"emotion": final_emotion, "duration": 2.0, "intensity": 1.0, "volume": 0.2}) + "\r\n").encode('utf-8'))
    else:
        ser.write((json.dumps({"emotion": emotion, "duration": 2.0, "intensity": 1.0, "volume": 1.22}) + "\r\n").encode('utf-8'))

    response = ser.readline().decode('utf-8').strip()
    print(f"Response: {response}")

ser.close()
print("–ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")